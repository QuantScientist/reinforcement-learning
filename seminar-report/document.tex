\documentclass{article} % For LaTeX2e
\usepackage{nips13submit_e,times}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{url}
\usepackage[
abbreviate=false,
backend=biber,
sortcites=true,
sorting=nyt,
sortlocale=en_US,
style=numeric-verb,
maxnames=10
]{biblatex}                     % Bibliography support

\newcommand{\setof}[1]{\ensuremath{\left \{ #1 \right \}}}

\title{Contextual Bandit and Reinforcement Learning Approaches to Targeted
Advertising}


\author{
Eric Andrews \\
Seminar: Reinforcement Learning and Its Applications, Spring 2014 \\
Department of Computer Science, University of Helsinki\\\\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}


\nipsfinalcopy % Uncomment for camera-ready version

\bibliography{sources.bib}
\begin{document}


\maketitle

\begin{abstract}
  TODO
\end{abstract}

\section{Introduction}

In an age where a huge amount of information and news can be found
free-of-charge online, many content producers on the Internet rely on
advertisement revenues to fund their operations. Often this advertisement is
deployed in the form of clickable banner ads, either textual, graphical,
animated or even interactive content, usually separated from the main content,
and designed to attract the interest of visitors. When a visitor clicks such a
banner, they are redirected to the advertiser's site, and the content producer
is financially compensated for the referral.

In this kind of advertising, it is the interest of the content producer to
maximize click-through rate (CTR) of the banner ads: the number of times
clicked divided by the number of times shown. If a content producer has several
ad banners it could show to the user, one strategy could be just to fill up the
web site with ads. However this can quickly lead to user annoyance, and in the
worst scenario, cause users to leave the site. Further, the effectiveness of
the advertisements starts to wither as more slots for banners are introduced.

An alternative strategy is to recognize that there is a limit to the number of
viable banner slots, and attempt to somehow selectively choose the ads to show
according to whom the ad is being displayed to. This is often referred to as
\emph{targeted advertising} or \emph{behavioral targeting}. By adding some
intelligence, we can attempt to show the user advertisements he or she could
potentially be interested in instead of just uniformly picking one out of a
bunch.

% TODO: use of term: targeted advertising vs. behavioral targeting

% TODO: an clump of unsubstantiated claims; find some sources...

This paper introduces two approaches to targeted advertising. First the
simpler, multi-armed bandit model is explored in some detail. It is the classic
example through which the exploration vs.  exploitation trade-off has been
studied. We then delve into some modifications of the model that are useful in
this setting of banner ad selection. After going through this simple model, a
more complex approach called reinforcement learning is considered. This
approach allows us to take into consideration situations in which the agent,
the ad system, can affect the state of the user, e.g. make them annoyed so that
they leave the site.


\begin{itemize}
  \item
  Other approaches, prior research..
  \item
  Related stuff (information retrieval, real-time bidding strategies)
\end{itemize}

\section{Approaches}


\subsection{Contextual bandit}
\begin{itemize}
  \item{Exploration / exploitation}
  \item{Introduce the contextual $n$-arms bandit problem.}
  \item{Discuss UCB, Thompson sampling, (and fully Bayesian approaches?)}
  \item{Mortal multi-armed bandits: old arms (ads) are removed and new ones
    born.}
  \item{Real world empirical results}
\end{itemize}

In the standard $n$-armed bandit problem, we are facing a slot machine with $n$
levers. Each lever is associated with some distinct probability distribution
that determines the amount of reward received from pulling that lever. Assuming
that pulling a lever is free but that we have a limited number of pulls, how to
we maximize the expected total reward given that we don't know the underlying
distributions? \cite{book}

In the above situation, the \emph{exploration vs. exploitation} dilemma is
highlighted. After playing for a bit, we may get a sense that some lever has
rewarded us better than the rest based on our experience so far. Do we, then,
greedily continue playing that arm till the end, \emph{exploiting} our current
knowledge? Or should we still \emph{explore} the other levers, in case we have
had bad luck and another lever has better payout in the long run? These are the
questions that bandit algorithms attempt to answer in an optimal way.

We are especially interested in a generalization of the $n$-armed bandit
problem, namely the \emph{contextual multi-armed bandit}
\cite{langford2007epoch}, in which we receive some side-information, a context,
before having to choose the lever to pull. The setting has been outlined below.
\begin{itemize}
  \item[]
    \textbf{For} $t = 1, ..., T$ (rounds)
    \begin{enumerate}
      \item{Receive some context $x_t$.}
      \item{Choose action  $a_i$ (pull lever), where $i \in \setof{1,...,n}$.}
      \item{Receive reward $r_t \in \mathbb{R}$.}
    \end{enumerate}
\end{itemize}

It should be stated that even though at first glance, the multi-armed bandit
may seem like a very contrived problem, it is actually a very general
framework. In the case of targeted advertising, we can think of it as follows.
The agent making the decisions is the website. The levers to pull are all the
possible ads that can be shown in some banner slot. The reward received is 1 if
a user clicks the ad and 0 otherwise. The context is some information gathered
on the user, e.g. what pages they have visited, gender, interests, age and so
on.


\subsection{Reinforcement learning}

\begin{itemize}
  \item{Introduce the referencement learning setting: MDP, value-functions
    etc.}
  \item{Introduce TD-learning and TD($\lambda$)-learning algorithms.}
  \item{Introduce concurrent reinforcement learning.}
\end{itemize}

\section{Conclusions}

\subsubsection*{References}
\nocite{*}

\printbibliography[heading=none]


\end{document}
